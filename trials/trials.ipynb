{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a955af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharad/Public/agentic_rag_system/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 114.73it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for vector search...\n",
      "Preparing BM25 for keyword search...\n",
      "\n",
      "############################################################\n",
      "QUERY: 'artificial intelligence in medicine'\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "DENSE VECTOR SEARCH RESULTS\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 0.6154, Index: 2)\n",
      "Document: Artificial intelligence transforms modern healthcare.\n",
      "\n",
      "Result #2 (Score: 0.5323, Index: 9)\n",
      "Document: Healthcare AI applications improve patient diagnosis accuracy.\n",
      "\n",
      "Result #3 (Score: 0.4651, Index: 1)\n",
      "Document: Machine learning is a subset of artificial intelligence.\n",
      "\n",
      "\n",
      "============================================================\n",
      "SPARSE KEYWORD SEARCH (BM25) RESULTS\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 4.7309, Index: 2)\n",
      "Document: Artificial intelligence transforms modern healthcare.\n",
      "\n",
      "Result #2 (Score: 2.0219, Index: 8)\n",
      "Document: Foxes are wild animals found in forests and urban areas.\n",
      "\n",
      "Result #3 (Score: 1.6736, Index: 1)\n",
      "Document: Machine learning is a subset of artificial intelligence.\n",
      "\n",
      "\n",
      "============================================================\n",
      "HYBRID SEARCH - EARLY FUSION (α=0.5)\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 1.0000, Index: 2)\n",
      "Document: Artificial intelligence transforms modern healthcare.\n",
      "\n",
      "Result #2 (Score: 0.3051, Index: 9)\n",
      "Document: Healthcare AI applications improve patient diagnosis accuracy.\n",
      "\n",
      "Result #3 (Score: 0.1477, Index: 1)\n",
      "Document: Machine learning is a subset of artificial intelligence.\n",
      "\n",
      "\n",
      "============================================================\n",
      "HYBRID SEARCH - RE-RANKING\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 1.0000, Index: 2)\n",
      "Document: Artificial intelligence transforms modern healthcare.\n",
      "\n",
      "Result #2 (Score: 0.3294, Index: 1)\n",
      "Document: Machine learning is a subset of artificial intelligence.\n",
      "\n",
      "Result #3 (Score: 0.0570, Index: 8)\n",
      "Document: Foxes are wild animals found in forests and urban areas.\n",
      "\n",
      "\n",
      "############################################################\n",
      "QUERY: 'pets and animals'\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "DENSE VECTOR SEARCH RESULTS\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 0.5024, Index: 10)\n",
      "Document: Pet ownership has positive effects on mental health.\n",
      "\n",
      "Result #2 (Score: 0.4938, Index: 3)\n",
      "Document: Dogs are loyal pets that enjoy playing fetch.\n",
      "\n",
      "Result #3 (Score: 0.4469, Index: 13)\n",
      "Document: Wildlife conservation efforts protect endangered species.\n",
      "\n",
      "\n",
      "============================================================\n",
      "SPARSE KEYWORD SEARCH (BM25) RESULTS\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 3.5249, Index: 8)\n",
      "Document: Foxes are wild animals found in forests and urban areas.\n",
      "\n",
      "Result #2 (Score: 2.2515, Index: 3)\n",
      "Document: Dogs are loyal pets that enjoy playing fetch.\n",
      "\n",
      "Result #3 (Score: 1.5030, Index: 5)\n",
      "Document: Cats are independent animals that sleep most of the day.\n",
      "\n",
      "\n",
      "============================================================\n",
      "HYBRID SEARCH - EARLY FUSION (α=0.5)\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 0.6276, Index: 3)\n",
      "Document: Dogs are loyal pets that enjoy playing fetch.\n",
      "\n",
      "Result #2 (Score: 0.5985, Index: 8)\n",
      "Document: Foxes are wild animals found in forests and urban areas.\n",
      "\n",
      "Result #3 (Score: 0.5000, Index: 10)\n",
      "Document: Pet ownership has positive effects on mental health.\n",
      "\n",
      "\n",
      "============================================================\n",
      "HYBRID SEARCH - RE-RANKING\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 0.6851, Index: 3)\n",
      "Document: Dogs are loyal pets that enjoy playing fetch.\n",
      "\n",
      "Result #2 (Score: 0.6047, Index: 8)\n",
      "Document: Foxes are wild animals found in forests and urban areas.\n",
      "\n",
      "Result #3 (Score: 0.0000, Index: 5)\n",
      "Document: Cats are independent animals that sleep most of the day.\n",
      "\n",
      "\n",
      "############################################################\n",
      "QUERY: 'machine learning with Python'\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "DENSE VECTOR SEARCH RESULTS\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 0.6316, Index: 12)\n",
      "Document: Data scientists use Python for machine learning projects.\n",
      "\n",
      "Result #2 (Score: 0.5103, Index: 7)\n",
      "Document: Python is a popular programming language for data science.\n",
      "\n",
      "Result #3 (Score: 0.4918, Index: 1)\n",
      "Document: Machine learning is a subset of artificial intelligence.\n",
      "\n",
      "\n",
      "============================================================\n",
      "SPARSE KEYWORD SEARCH (BM25) RESULTS\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 4.6106, Index: 12)\n",
      "Document: Data scientists use Python for machine learning projects.\n",
      "\n",
      "Result #2 (Score: 3.5148, Index: 6)\n",
      "Document: Deep learning uses neural networks with multiple layers.\n",
      "\n",
      "Result #3 (Score: 2.9370, Index: 1)\n",
      "Document: Machine learning is a subset of artificial intelligence.\n",
      "\n",
      "\n",
      "============================================================\n",
      "HYBRID SEARCH - EARLY FUSION (α=0.5)\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 1.0000, Index: 12)\n",
      "Document: Data scientists use Python for machine learning projects.\n",
      "\n",
      "Result #2 (Score: 0.4216, Index: 1)\n",
      "Document: Machine learning is a subset of artificial intelligence.\n",
      "\n",
      "Result #3 (Score: 0.3190, Index: 6)\n",
      "Document: Deep learning uses neural networks with multiple layers.\n",
      "\n",
      "\n",
      "============================================================\n",
      "HYBRID SEARCH - RE-RANKING\n",
      "============================================================\n",
      "\n",
      "Result #1 (Score: 1.0000, Index: 12)\n",
      "Document: Data scientists use Python for machine learning projects.\n",
      "\n",
      "Result #2 (Score: 0.4779, Index: 1)\n",
      "Document: Machine learning is a subset of artificial intelligence.\n",
      "\n",
      "Result #3 (Score: 0.3190, Index: 6)\n",
      "Document: Deep learning uses neural networks with multiple layers.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 105.29it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for vector search...\n",
      "Preparing BM25 for keyword search...\n",
      "\n",
      "================================================================================\n",
      "COMPARISON OF RETRIEVAL TECHNIQUES\n",
      "================================================================================\n",
      "Query: 'AI doctor diagnosis medical'\n",
      "Document count: 10\n",
      "\n",
      "Top 5 Results Comparison:\n",
      "\n",
      "Rank  Document Snippet                         Vector     BM25      \n",
      "--------------------------------------------------------------------------------\n",
      "0     Artificial intelligence helps doctors di... 0.6569     0.0000    \n",
      "1     Machine learning algorithms analyze medi... 0.4216     0.3635    \n",
      "2     AI in healthcare improves patient outcom... 0.5735     0.0000    \n",
      "3     Doctors use AI tools for early cancer de... 0.5594     0.0000    \n",
      "4     Healthcare technology includes telemedic... 0.5548     0.0000    \n",
      "5     Medical AI must comply with strict priva... 0.5145     0.3635    \n",
      "6     Deep learning models can predict patient... 0.4184     0.0000    \n",
      "7     Natural language processing extracts inf... 0.4624     0.3635    \n",
      "8     Robotic surgery assisted by AI increases... 0.4912     0.0000    \n",
      "9     AI-powered chatbots provide basic medica... 0.5564     0.3635    \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import faiss\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HybridSearchRetriever:\n",
    "    \"\"\"\n",
    "    A comprehensive retriever implementing:\n",
    "    1. Dense Vector Search (semantic similarity)\n",
    "    2. Sparse Keyword Search (BM25)\n",
    "    3. Hybrid Search (combination of both)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the retriever with embedding model.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Sentence transformer model for embeddings\n",
    "        \"\"\"\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "        self.documents = []\n",
    "        self.document_embeddings = None\n",
    "        self.bm25 = None\n",
    "        self.index = None\n",
    "        self.tokenized_corpus = None\n",
    "        \n",
    "    def preprocess_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Simple text preprocessing for BM25 tokenization.\"\"\"\n",
    "        return text.lower().split()\n",
    "    \n",
    "    def index_documents(self, documents: List[str]):\n",
    "        \"\"\"\n",
    "        Index documents for both vector and keyword search.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of text documents to index\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        \n",
    "        # 1. Create embeddings for dense vector search\n",
    "        print(\"Creating embeddings for vector search...\")\n",
    "        self.document_embeddings = self.embedding_model.encode(\n",
    "            documents, \n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "        \n",
    "        # Create FAISS index for efficient similarity search\n",
    "        dimension = self.document_embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dimension)  # L2 distance\n",
    "        self.index.add(self.document_embeddings)\n",
    "        \n",
    "        # 2. Prepare BM25 for sparse keyword search\n",
    "        print(\"Preparing BM25 for keyword search...\")\n",
    "        self.tokenized_corpus = [self.preprocess_text(doc) for doc in documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "    \n",
    "    def dense_vector_search(self, \n",
    "                           query: str, \n",
    "                           k: int = 5) -> List[Tuple[int, float, str]]:\n",
    "        \"\"\"\n",
    "        Perform semantic search using vector embeddings.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of (index, score, document) tuples\n",
    "        \"\"\"\n",
    "        # Encode query\n",
    "        query_embedding = self.embedding_model.encode(\n",
    "            [query], \n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "        \n",
    "        # Search in FAISS index\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        \n",
    "        # Convert L2 distance to similarity score (higher is better)\n",
    "        # Using 1/(1+distance) to convert distance to similarity\n",
    "        results = []\n",
    "        for idx, distance in zip(indices[0], distances[0]):\n",
    "            if idx != -1:  # Valid index\n",
    "                similarity = 1 / (1 + distance)  # Convert distance to similarity\n",
    "                results.append((int(idx), float(similarity), self.documents[idx]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def sparse_keyword_search(self, \n",
    "                             query: str, \n",
    "                             k: int = 5) -> List[Tuple[int, float, str]]:\n",
    "        \"\"\"\n",
    "        Perform keyword-based search using BM25.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of (index, score, document) tuples\n",
    "        \"\"\"\n",
    "        tokenized_query = self.preprocess_text(query)\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        # Get top-k indices\n",
    "        top_k_indices = np.argsort(scores)[::-1][:k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_k_indices:\n",
    "            if scores[idx] > 0:  # Only include documents with positive scores\n",
    "                results.append((int(idx), float(scores[idx]), self.documents[idx]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def hybrid_search_early_fusion(self, \n",
    "                                  query: str, \n",
    "                                  k: int = 5,\n",
    "                                  alpha: float = 0.5) -> List[Tuple[int, float, str]]:\n",
    "        \"\"\"\n",
    "        Hybrid search using early fusion (combine scores before ranking).\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of results to return\n",
    "            alpha: Weight for vector search (1-alpha for BM25)\n",
    "                   alpha=1: pure vector search, alpha=0: pure BM25\n",
    "            \n",
    "        Returns:\n",
    "            List of (index, score, document) tuples\n",
    "        \"\"\"\n",
    "        # Get results from both methods\n",
    "        vector_results = self.dense_vector_search(query, k * 2)\n",
    "        bm25_results = self.sparse_keyword_search(query, k * 2)\n",
    "        \n",
    "        # Create dictionaries for scores\n",
    "        vector_scores = {idx: score for idx, score, _ in vector_results}\n",
    "        bm25_scores = {idx: score for idx, score, _ in bm25_results}\n",
    "        \n",
    "        # Normalize scores to [0, 1] range\n",
    "        def normalize_scores(score_dict):\n",
    "            if not score_dict:\n",
    "                return {}\n",
    "            values = np.array(list(score_dict.values()))\n",
    "            if values.max() == values.min():\n",
    "                return {k: 0.5 for k in score_dict.keys()}\n",
    "            normalized = (values - values.min()) / (values.max() - values.min())\n",
    "            return dict(zip(score_dict.keys(), normalized))\n",
    "        \n",
    "        norm_vector = normalize_scores(vector_scores)\n",
    "        norm_bm25 = normalize_scores(bm25_scores)\n",
    "        \n",
    "        # Combine scores\n",
    "        combined_scores = {}\n",
    "        all_indices = set(vector_scores.keys()) | set(bm25_scores.keys())\n",
    "        \n",
    "        for idx in all_indices:\n",
    "            vector_score = norm_vector.get(idx, 0)\n",
    "            bm25_score = norm_bm25.get(idx, 0)\n",
    "            combined_score = (alpha * vector_score) + ((1 - alpha) * bm25_score)\n",
    "            combined_scores[idx] = combined_score\n",
    "        \n",
    "        # Sort by combined score\n",
    "        sorted_indices = sorted(combined_scores.items(), \n",
    "                               key=lambda x: x[1], \n",
    "                               reverse=True)[:k]\n",
    "        \n",
    "        results = []\n",
    "        for idx, score in sorted_indices:\n",
    "            results.append((idx, score, self.documents[idx]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def hybrid_search_reranking(self, \n",
    "                               query: str, \n",
    "                               k: int = 5,\n",
    "                               first_stage_k: int = 20) -> List[Tuple[int, float, str]]:\n",
    "        \"\"\"\n",
    "        Hybrid search using re-ranking approach (BM25 first, then re-rank with vectors).\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of results to return\n",
    "            first_stage_k: Number of initial BM25 results to re-rank\n",
    "            \n",
    "        Returns:\n",
    "            List of (index, score, document) tuples\n",
    "        \"\"\"\n",
    "        # Stage 1: Get initial results from BM25\n",
    "        bm25_results = self.sparse_keyword_search(query, first_stage_k)\n",
    "        \n",
    "        if not bm25_results:\n",
    "            return []\n",
    "        \n",
    "        # Stage 2: Re-rank using vector similarity\n",
    "        bm25_indices = [idx for idx, _, _ in bm25_results]\n",
    "        \n",
    "        # Get embeddings for the BM25 results\n",
    "        query_embedding = self.embedding_model.encode([query], convert_to_numpy=True)\n",
    "        result_embeddings = self.document_embeddings[bm25_indices]\n",
    "        \n",
    "        # Calculate cosine similarities\n",
    "        # Cosine similarity = dot product of normalized vectors\n",
    "        query_norm = query_embedding / np.linalg.norm(query_embedding)\n",
    "        result_norms = result_embeddings / np.linalg.norm(result_embeddings, axis=1, keepdims=True)\n",
    "        similarities = np.dot(result_norms, query_norm.T).flatten()\n",
    "        \n",
    "        # Combine scores: weighted average of BM25 and vector similarity\n",
    "        bm25_scores = np.array([score for _, score, _ in bm25_results])\n",
    "        \n",
    "        # Normalize both scores\n",
    "        bm25_norm = (bm25_scores - bm25_scores.min()) / (bm25_scores.max() - bm25_scores.min() + 1e-10)\n",
    "        similarities_norm = (similarities - similarities.min()) / (similarities.max() - similarities.min() + 1e-10)\n",
    "        \n",
    "        # Combine with equal weight (can be adjusted)\n",
    "        combined_scores = 0.5 * bm25_norm + 0.5 * similarities_norm\n",
    "        \n",
    "        # Get top-k results\n",
    "        top_k_indices = np.argsort(combined_scores)[::-1][:k]\n",
    "        \n",
    "        results = []\n",
    "        for i in top_k_indices:\n",
    "            idx = bm25_indices[i]\n",
    "            score = combined_scores[i]\n",
    "            results.append((idx, score, self.documents[idx]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def display_results(self, \n",
    "                       results: List[Tuple[int, float, str]], \n",
    "                       title: str):\n",
    "        \"\"\"Helper function to display search results.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{title}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for i, (idx, score, doc) in enumerate(results, 1):\n",
    "            print(f\"\\nResult #{i} (Score: {score:.4f}, Index: {idx})\")\n",
    "            print(f\"Document: {doc[:100]}...\" if len(doc) > 100 else f\"Document: {doc}\")\n",
    "        print()\n",
    "\n",
    "# Example Usage\n",
    "def main():\n",
    "    # Sample documents\n",
    "    documents = [\n",
    "        \"The quick brown fox jumps over the lazy dog.\",\n",
    "        \"Machine learning is a subset of artificial intelligence.\",\n",
    "        \"Artificial intelligence transforms modern healthcare.\",\n",
    "        \"Dogs are loyal pets that enjoy playing fetch.\",\n",
    "        \"Natural language processing enables computers to understand human language.\",\n",
    "        \"Cats are independent animals that sleep most of the day.\",\n",
    "        \"Deep learning uses neural networks with multiple layers.\",\n",
    "        \"Python is a popular programming language for data science.\",\n",
    "        \"Foxes are wild animals found in forests and urban areas.\",\n",
    "        \"Healthcare AI applications improve patient diagnosis accuracy.\",\n",
    "        \"Pet ownership has positive effects on mental health.\",\n",
    "        \"Transformers architecture revolutionized natural language processing.\",\n",
    "        \"Data scientists use Python for machine learning projects.\",\n",
    "        \"Wildlife conservation efforts protect endangered species.\",\n",
    "        \"Neural networks mimic the human brain's structure.\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize retriever\n",
    "    retriever = HybridSearchRetriever()\n",
    "    retriever.index_documents(documents)\n",
    "    \n",
    "    # Test queries\n",
    "    queries = [\n",
    "        \"artificial intelligence in medicine\",\n",
    "        \"pets and animals\",\n",
    "        \"machine learning with Python\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"QUERY: '{query}'\")\n",
    "        print(f\"{'#'*60}\")\n",
    "        \n",
    "        # 1. Dense Vector Search (Semantic Similarity)\n",
    "        vector_results = retriever.dense_vector_search(query, k=3)\n",
    "        retriever.display_results(vector_results, \"DENSE VECTOR SEARCH RESULTS\")\n",
    "        \n",
    "        # 2. Sparse Keyword Search (BM25)\n",
    "        bm25_results = retriever.sparse_keyword_search(query, k=3)\n",
    "        retriever.display_results(bm25_results, \"SPARSE KEYWORD SEARCH (BM25) RESULTS\")\n",
    "        \n",
    "        # 3. Hybrid Search - Early Fusion\n",
    "        hybrid_results = retriever.hybrid_search_early_fusion(query, k=3, alpha=0.5)\n",
    "        retriever.display_results(hybrid_results, \"HYBRID SEARCH - EARLY FUSION (α=0.5)\")\n",
    "        \n",
    "        # 4. Hybrid Search - Re-ranking\n",
    "        rerank_results = retriever.hybrid_search_reranking(query, k=3)\n",
    "        retriever.display_results(rerank_results, \"HYBRID SEARCH - RE-RANKING\")\n",
    "\n",
    "def compare_techniques():\n",
    "    \"\"\"Compare different retrieval techniques on specific queries.\"\"\"\n",
    "    \n",
    "    # More focused documents\n",
    "    tech_docs = [\n",
    "        \"Artificial intelligence helps doctors diagnose diseases faster.\",\n",
    "        \"Machine learning algorithms analyze medical images for tumors.\",\n",
    "        \"AI in healthcare improves patient outcomes and reduces costs.\",\n",
    "        \"Doctors use AI tools for early cancer detection.\",\n",
    "        \"Healthcare technology includes telemedicine and AI diagnostics.\",\n",
    "        \"Medical AI must comply with strict privacy regulations.\",\n",
    "        \"Deep learning models can predict patient readmission rates.\",\n",
    "        \"Natural language processing extracts information from medical records.\",\n",
    "        \"Robotic surgery assisted by AI increases precision.\",\n",
    "        \"AI-powered chatbots provide basic medical advice to patients.\"\n",
    "    ]\n",
    "    \n",
    "    retriever = HybridSearchRetriever()\n",
    "    retriever.index_documents(tech_docs)\n",
    "    \n",
    "    query = \"AI doctor diagnosis medical\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARISON OF RETRIEVAL TECHNIQUES\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Document count: {len(tech_docs)}\")\n",
    "    \n",
    "    # Get all results\n",
    "    vector_all = retriever.dense_vector_search(query, k=len(tech_docs))\n",
    "    bm25_all = retriever.sparse_keyword_search(query, k=len(tech_docs))\n",
    "    \n",
    "    print(\"\\nTop 5 Results Comparison:\")\n",
    "    print(\"\\n{:<5} {:<40} {:<10} {:<10}\".format(\n",
    "        \"Rank\", \"Document Snippet\", \"Vector\", \"BM25\"))\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Create dictionaries for easy lookup\n",
    "    vector_dict = {idx: (score, doc) for idx, score, doc in vector_all}\n",
    "    bm25_dict = {idx: (score, doc) for idx, score, doc in bm25_all}\n",
    "    \n",
    "    all_indices = set(vector_dict.keys()) | set(bm25_dict.keys())\n",
    "    \n",
    "    # Show each document's scores from both methods\n",
    "    for idx in all_indices:\n",
    "        vec_score = vector_dict.get(idx, (0, \"\"))[0]\n",
    "        bm25_score = bm25_dict.get(idx, (0, \"\"))[0]\n",
    "        doc_snippet = vector_dict.get(idx, (0, \"\"))[1]\n",
    "        if doc_snippet == \"\":\n",
    "            doc_snippet = bm25_dict.get(idx, (0, \"\"))[1]\n",
    "        \n",
    "        print(\"{:<5} {:<40} {:<10.4f} {:<10.4f}\".format(\n",
    "            idx, \n",
    "            doc_snippet[:40] + \"...\", \n",
    "            vec_score, \n",
    "            bm25_score\n",
    "        ))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run main example\n",
    "    main()\n",
    "    \n",
    "    # Run comparison\n",
    "    compare_techniques()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
